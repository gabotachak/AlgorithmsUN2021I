{
 "cells": [
  {
   "source": [
    "# Introduction to Financial Python\n",
    "## Pandas-Resampling and DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Introduction\n",
    "In the last chapter we had a glimpse of Pandas. In this chapter we will learn about resampling methods and the DataFrame object, which is a powerful tool for financial data analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Fetching Data\n",
    "Here we use the Quandl API to retrieve data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "We will create a Series named \"aapl\" whose values are Apple's daily closing prices, which are of course indexed by dates:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-03    114.715378\n2017-01-04    114.586983\n2017-01-05    115.169696\n2017-01-06    116.453639\n2017-01-09    117.520300\n                 ...    \n2017-12-22    175.010000\n2017-12-26    170.570000\n2017-12-27    170.600000\n2017-12-28    171.080000\n2017-12-29    169.230000\nName: Adj. Close, Length: 249, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "aapl_table = quandl.get('WIKI/AAPL')\n",
    "aapl = aapl_table['Adj. Close']['2017']\n",
    "print(aapl)"
   ]
  },
  {
   "source": [
    "Recall that we can fetch a specific data point using ```series['yyyy-mm-dd']```. We can also fetch the data in a specific month using ```series['yyyy-mm']```.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-03-01    138.657681\n2017-03-02    137.834404\n2017-03-03    138.647762\n2017-03-06    138.211326\n2017-03-07    138.389868\n2017-03-08    137.874080\n2017-03-09    137.556672\n2017-03-10    138.012946\n2017-03-13    138.072460\n2017-03-14    137.864161\n2017-03-15    139.322254\n2017-03-16    139.550391\n2017-03-17    138.856061\n2017-03-20    140.314154\n2017-03-21    138.707276\n2017-03-22    140.274478\n2017-03-23    139.778528\n2017-03-24    139.500796\n2017-03-27    139.738852\n2017-03-28    142.635200\n2017-03-29    142.952608\n2017-03-30    142.764147\n2017-03-31    142.496334\nName: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(aapl['2017-3'])"
   ]
  },
  {
   "source": [
    "Or in several consecutive months:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-02-01    127.159749\n",
       "2017-02-02    126.942467\n",
       "2017-02-03    127.485673\n",
       "2017-02-06    128.680728\n",
       "2017-02-07    129.905412\n",
       "                 ...    \n",
       "2017-04-24    142.476496\n",
       "2017-04-25    143.369205\n",
       "2017-04-26    142.487208\n",
       "2017-04-27    142.625281\n",
       "2017-04-28    142.486415\n",
       "Name: Adj. Close, Length: 61, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "aapl['2017-2':'2017-4']"
   ]
  },
  {
   "source": [
    "```.head(N)``` and ```.tail(N)``` are methods for quickly accessing the first or last N elements."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-03    114.715378\n2017-01-04    114.586983\n2017-01-05    115.169696\n2017-01-06    116.453639\n2017-01-09    117.520300\nName: Adj. Close, dtype: float64\nDate\n2017-12-15    173.87\n2017-12-18    176.42\n2017-12-19    174.54\n2017-12-20    174.35\n2017-12-21    175.01\n2017-12-22    175.01\n2017-12-26    170.57\n2017-12-27    170.60\n2017-12-28    171.08\n2017-12-29    169.23\nName: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(aapl.head(5))\n",
    "print(aapl.tail(10))"
   ]
  },
  {
   "source": [
    "### Resampling\n",
    "```series.resample(freq)``` is a class called \"DatetimeIndexResampler\" which groups data in a Series object into regular time intervals. The argument \"freq\" determines the length of each interval.\n",
    "\n",
    "```series.resample.mean()``` is a complete statement that groups data into intervals, and then compute the mean of each interval. For example, if we want to aggregate the daily data into monthly data by mean:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-31    118.093136\n2017-02-28    132.456268\n2017-03-31    139.478802\n2017-04-30    141.728436\n2017-05-31    151.386305\n2017-06-30    147.233064\n2017-07-31    147.706190\n2017-08-31    158.856375\n2017-09-30    157.606500\n2017-10-31    157.811627\n2017-11-30    172.214500\n2017-12-31    171.893100\nFreq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "by_month = aapl.resample('M').mean()\n",
    "print(by_month)"
   ]
  },
  {
   "source": [
    "We can also aggregate the data by week:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-08    115.231424\n2017-01-15    117.755360\n2017-01-22    118.461035\n2017-01-29    119.667448\n2017-02-05    124.313346\nFreq: W-SUN, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "by_week = aapl.resample('W').mean()\n",
    "print(by_week.head())"
   ]
  },
  {
   "source": [
    "We can choose almost any frequency by using the format 'nf', where 'n' is an integer and 'f' is M for month, W for week and D for day."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-01-31    120.443739\n",
       "2017-02-28    135.999390\n",
       "2017-03-31    142.952608\n",
       "2017-04-30    143.597342\n",
       "2017-05-31    155.469192\n",
       "2017-06-30    154.821818\n",
       "2017-07-31    152.839860\n",
       "2017-08-31    164.000000\n",
       "2017-09-30    164.050000\n",
       "2017-10-31    169.040000\n",
       "2017-11-30    175.880000\n",
       "2017-12-31    176.420000\n",
       "Freq: M, Name: Adj. Close, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "aapl.resample('M').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_day = aapl.resample('3D').mean()\n",
    "two_week = aapl.resample('2W').mean()\n",
    "two_month = aapl.resample('2M').mean()"
   ]
  },
  {
   "source": [
    "Besides the mean() method, other methods can also be used with the resampler:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = aapl.resample('W').std() # standard deviation\n",
    "max = aapl.resample('W').max() # maximum value\n",
    "min = aapl.resample('W').min() # minimum "
   ]
  },
  {
   "source": [
    "Often we want to calculate monthly returns of a stock, based on prices on the last day of each month. To fetch those prices, we use the series.resample.agg() method:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-31    119.851150\n2017-02-28    135.880362\n2017-03-31    142.496334\n2017-04-30    142.486415\n2017-05-31    152.142689\n2017-06-30    143.438008\n2017-07-31    148.248489\n2017-08-31    164.000000\n2017-09-30    154.120000\n2017-10-31    169.040000\n2017-11-30    171.850000\n2017-12-31    169.230000\nFreq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "last_day = aapl.resample('M').agg(lambda x: x[-1])\n",
    "print(last_day)"
   ]
  },
  {
   "source": [
    "Or directly calculate the monthly rates of return using the data for the first day and the last day:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n",
      "2017-01-31    0.045940\n",
      "2017-02-28    0.070409\n",
      "2017-03-31    0.033823\n",
      "2017-04-30   -0.007736\n",
      "2017-05-31    0.039829\n",
      "2017-06-30   -0.073528\n",
      "2017-07-31    0.033035\n",
      "2017-08-31    0.047890\n",
      "2017-09-30   -0.049112\n",
      "2017-10-31    0.094252\n",
      "2017-11-30    0.022247\n",
      "2017-12-31   -0.003357\n",
      "Freq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[1] - 1)\n",
    "print(monthly_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_week = aapl.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-01-31    1.781512\n",
       "2017-03-31    4.323834\n",
       "2017-05-31    5.454495\n",
       "2017-07-31    3.865333\n",
       "2017-09-30    3.634223\n",
       "2017-11-30    8.011704\n",
       "2018-01-31    2.291229\n",
       "Freq: 2M, Name: Adj. Close, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "twomon = aapl.resample('2M').std()\n",
    "twomon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-01-31    119.851150\n",
       "2017-02-28    135.880362\n",
       "2017-03-31    142.496334\n",
       "2017-04-30    142.486415\n",
       "2017-05-31    152.142689\n",
       "2017-06-30    143.438008\n",
       "2017-07-31    148.248489\n",
       "2017-08-31    164.000000\n",
       "2017-09-30    154.120000\n",
       "2017-10-31    169.040000\n",
       "2017-11-30    171.850000\n",
       "2017-12-31    169.230000\n",
       "Freq: M, Name: Adj. Close, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "last_day = aapl.resample('M').agg(lambda x: x[-1])\n",
    "last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-01-31    0.045940\n",
       "2017-02-28    0.070409\n",
       "2017-03-31    0.033823\n",
       "2017-04-30   -0.007736\n",
       "2017-05-31    0.039829\n",
       "2017-06-30   -0.073528\n",
       "2017-07-31    0.033035\n",
       "2017-08-31    0.047890\n",
       "2017-09-30   -0.049112\n",
       "2017-10-31    0.094252\n",
       "2017-11-30    0.022247\n",
       "2017-12-31   -0.003357\n",
       "Freq: M, Name: Adj. Close, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[1] - 1)\n",
    "monthly_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.02114094011940022\n",
      "0.047756528642233134\n",
      "0.09425168306576914\n"
     ]
    }
   ],
   "source": [
    "print(monthly_return.mean())\n",
    "print(monthly_return.std())\n",
    "print(monthly_return.max())"
   ]
  },
  {
   "source": [
    "Another two methods frequently used on Series are ```.diff()``` and ```.pct_change()```. The former calculates the difference between consecutive elements, and the latter calculates the percentage change."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n",
      "2017-01-31          NaN\n",
      "2017-02-28    16.029211\n",
      "2017-03-31     6.615972\n",
      "2017-04-30    -0.009919\n",
      "2017-05-31     9.656274\n",
      "2017-06-30    -8.704681\n",
      "2017-07-31     4.810482\n",
      "2017-08-31    15.751511\n",
      "2017-09-30    -9.880000\n",
      "2017-10-31    14.920000\n",
      "2017-11-30     2.810000\n",
      "2017-12-31    -2.620000\n",
      "Freq: M, Name: Adj. Close, dtype: float64\n",
      "Date\n",
      "2017-01-31         NaN\n",
      "2017-02-28    0.133743\n",
      "2017-03-31    0.048690\n",
      "2017-04-30   -0.000070\n",
      "2017-05-31    0.067770\n",
      "2017-06-30   -0.057214\n",
      "2017-07-31    0.033537\n",
      "2017-08-31    0.106251\n",
      "2017-09-30   -0.060244\n",
      "2017-10-31    0.096808\n",
      "2017-11-30    0.016623\n",
      "2017-12-31   -0.015246\n",
      "Freq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(last_day.diff())\n",
    "print(last_day.pct_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "count    249.000000\nmean     149.815713\nstd       15.065681\nmin      114.586983\n25%      140.651400\n50%      151.890000\n75%      159.780000\nmax      176.420000\nName: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(aapl.describe())"
   ]
  },
  {
   "source": [
    "Notice that we induced a NaN value while calculating percentage changes i.e. returns.\n",
    "\n",
    "When dealing with NaN values, we usually either removing the data point or fill it with a specific value. Here we fill it with 0:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-31    0.000000\n2017-02-28    0.133743\n2017-03-31    0.048690\n2017-04-30   -0.000070\n2017-05-31    0.067770\n2017-06-30   -0.057214\n2017-07-31    0.033537\n2017-08-31    0.106251\n2017-09-30   -0.060244\n2017-10-31    0.096808\n2017-11-30    0.016623\n2017-12-31   -0.015246\nFreq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = last_day.pct_change()\n",
    "print(daily_return.fillna(0))"
   ]
  },
  {
   "source": [
    "Alternatively, we can fill a NaN with the next fitted value. This is called 'backward fill', or 'bfill' in short:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2017-01-31    0.133743\n2017-02-28    0.133743\n2017-03-31    0.048690\n2017-04-30   -0.000070\n2017-05-31    0.067770\n2017-06-30   -0.057214\n2017-07-31    0.033537\n2017-08-31    0.106251\n2017-09-30   -0.060244\n2017-10-31    0.096808\n2017-11-30    0.016623\n2017-12-31   -0.015246\nFreq: M, Name: Adj. Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_return = last_day.pct_change()\n",
    "print(daily_return.fillna(method = 'bfill'))"
   ]
  },
  {
   "source": [
    "As expected, since there is a 'backward fill' method, there must be a 'forward fill' method, or 'ffill' in short. However we can't use it here because the NaN is the first value.\n",
    "\n",
    "We can also simply remove NaN values by ```.dropna()```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Date\n",
       "2017-02-28    0.133743\n",
       "2017-03-31    0.048690\n",
       "2017-04-30   -0.000070\n",
       "2017-05-31    0.067770\n",
       "2017-06-30   -0.057214\n",
       "2017-07-31    0.033537\n",
       "2017-08-31    0.106251\n",
       "2017-09-30   -0.060244\n",
       "2017-10-31    0.096808\n",
       "2017-11-30    0.016623\n",
       "2017-12-31   -0.015246\n",
       "Freq: M, Name: Adj. Close, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "daily_return = last_day.pct_change()\n",
    "daily_return.dropna()"
   ]
  },
  {
   "source": [
    "### DataFrame\n",
    "The DataFrame is the most commonly used data structure in Pandas. It is essentially a table, just like an Excel spreadsheet.\n",
    "\n",
    "More precisely, a DataFrame is a collection of Series objects, each of which may contain different data types. A DataFrame can be created from various data types: dictionary, 2-D numpy.ndarray, a Series or another DataFrame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Create DataFrames\n",
    "The most common method of creating a DataFrame is passing a dictionary:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              AAPL    GOOG     IBM\n2017-07-03  143.50  898.70  155.58\n2017-07-04  144.09  911.71  153.67\n2017-07-05  142.73  906.69  152.36\n2017-07-06  144.18  918.59  152.94\n2017-07-07  143.77  926.99  153.49\n"
     ]
    }
   ],
   "source": [
    "dict = {'AAPL': [143.5, 144.09, 142.73, 144.18, 143.77],'GOOG':[898.7, 911.71, 906.69, 918.59, 926.99],\n",
    "        'IBM':[155.58, 153.67, 152.36, 152.94, 153.49]}\n",
    "data_index = pd.date_range('2017-07-03',periods = 5, freq = 'D')\n",
    "df = pd.DataFrame(dict, index = data_index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     AAPL    GOOG\n0  143.50  898.70\n1  144.09  911.71\n2  142.73  906.69\n3  144.18  918.59\n4  143.77  926.99\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')\n",
    "s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')\n",
    "data_frame = pd.concat([s1,s2], axis = 1)\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['AAPL', 'GOOG', 'IBM'], dtype='object')\n",
      "2017-07-03    143.50\n",
      "2017-07-04    144.09\n",
      "2017-07-05    142.73\n",
      "2017-07-06    144.18\n",
      "2017-07-07    143.77\n",
      "Freq: D, Name: AAPL, dtype: float64\n",
      "2017-07-03    898.70\n",
      "2017-07-04    911.71\n",
      "2017-07-05    906.69\n",
      "2017-07-06    918.59\n",
      "2017-07-07    926.99\n",
      "Freq: D, Name: GOOG, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.AAPL)\n",
    "print(df['GOOG'])"
   ]
  },
  {
   "source": [
    "#### Manipulating DataFrames\n",
    "We can fetch values in a DataFrame by columns and index. Each column in a DataFrame is essentially a Pandas Series. We can fetch a column by square brackets: df['column_name']\n",
    "\n",
    "If a column name contains no spaces, then we can also use df.column_name to fetch a column:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n",
      "2018-03-21    171.270\n",
      "2018-03-22    168.845\n",
      "2018-03-23    164.940\n",
      "2018-03-26    172.770\n",
      "2018-03-27    168.340\n",
      "Name: Close, dtype: float64\n",
      "Date\n",
      "2018-03-21    35247358.0\n",
      "2018-03-22    41051076.0\n",
      "2018-03-23    40248954.0\n",
      "2018-03-26    36272617.0\n",
      "2018-03-27    38962839.0\n",
      "Name: Adj. Volume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = aapl_table\n",
    "print(df.Close.tail(5))\n",
    "print(df['Adj. Volume'].tail(5))"
   ]
  },
  {
   "source": [
    "All the methods we applied to a Series index such as ```iloc[]```, ```loc[]``` and resampling methods, can also be applied to a DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                    \n",
      "2016-01-31   94.79   97.3400   94.35   97.34  64416504.0          0.0   \n",
      "2016-02-29   96.86   98.2300   96.65   96.69  35216277.0          0.0   \n",
      "2016-03-31  109.72  109.9000  108.88  108.99  25888449.0          0.0   \n",
      "2016-04-30   93.99   94.7200   92.51   93.74  68531478.0          0.0   \n",
      "2016-05-31   99.60  100.4000   98.82   99.86  42307212.0          0.0   \n",
      "2016-06-30   94.44   95.7700   94.30   95.60  35836356.0          0.0   \n",
      "2016-07-31  104.19  104.5500  103.68  104.21  27733688.0          0.0   \n",
      "2016-08-31  105.66  106.5699  105.64  106.10  29662406.0          0.0   \n",
      "2016-09-30  112.46  113.3700  111.80  113.05  36379106.0          0.0   \n",
      "2016-10-31  113.65  114.2300  113.20  113.54  26419398.0          0.0   \n",
      "2016-11-30  111.56  112.2000  110.27  110.52  36162258.0          0.0   \n",
      "2016-12-31  116.65  117.2000  115.43  115.82  30586265.0          0.0   \n",
      "\n",
      "            Split Ratio   Adj. Open   Adj. High    Adj. Low  Adj. Close  \\\n",
      "Date                                                                      \n",
      "2016-01-31          1.0   91.581233   94.044912   91.156128   94.044912   \n",
      "2016-02-29          1.0   94.084911   95.415659   93.880927   93.919781   \n",
      "2016-03-31          1.0  106.576465  106.751308  105.760531  105.867380   \n",
      "2016-04-30          1.0   91.297138   92.006223   89.859540   91.054300   \n",
      "2016-05-31          1.0   97.337844   98.119674   96.575559   97.591939   \n",
      "2016-06-30          1.0   92.295040   93.594832   92.158220   93.428693   \n",
      "2016-07-31          1.0  101.823594  102.175417  101.325177  101.843140   \n",
      "2016-08-31          1.0  103.816156  104.710177  103.796505  104.248477   \n",
      "2016-09-30          1.0  110.497491  111.391610  109.849008  111.077195   \n",
      "2016-10-31          1.0  111.666724  112.236603  111.224577  111.558644   \n",
      "2016-11-30          1.0  110.182071  110.814166  108.908004  109.154917   \n",
      "2016-12-31          1.0  115.209202  115.752409  114.004271  114.389454   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2016-01-31   64416504.0  \n",
      "2016-02-29   35216277.0  \n",
      "2016-03-31   25888449.0  \n",
      "2016-04-30   68531478.0  \n",
      "2016-05-31   42307212.0  \n",
      "2016-06-30   35836356.0  \n",
      "2016-07-31   27733688.0  \n",
      "2016-08-31   29662406.0  \n",
      "2016-09-30   36379106.0  \n",
      "2016-10-31   26419398.0  \n",
      "2016-11-30   36162258.0  \n",
      "2016-12-31   30586265.0  \n",
      "<ipython-input-27-b2f3be7087f4>:1: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  aapl_2016 = df['2016']\n"
     ]
    }
   ],
   "source": [
    "aapl_2016 = df['2016']\n",
    "aapl_month = aapl_2016.resample('M').agg(lambda x: x[-1])\n",
    "print(aapl_month)"
   ]
  },
  {
   "source": [
    "We may select certain columns of a DataFrame using their names:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close\n",
      "Date                                        \n",
      "2016-01-31   94.79   97.3400   94.35   97.34\n",
      "2016-02-29   96.86   98.2300   96.65   96.69\n",
      "2016-03-31  109.72  109.9000  108.88  108.99\n",
      "2016-04-30   93.99   94.7200   92.51   93.74\n",
      "2016-05-31   99.60  100.4000   98.82   99.86\n",
      "2016-06-30   94.44   95.7700   94.30   95.60\n",
      "2016-07-31  104.19  104.5500  103.68  104.21\n",
      "2016-08-31  105.66  106.5699  105.64  106.10\n",
      "2016-09-30  112.46  113.3700  111.80  113.05\n",
      "2016-10-31  113.65  114.2300  113.20  113.54\n",
      "2016-11-30  111.56  112.2000  110.27  110.52\n",
      "2016-12-31  116.65  117.2000  115.43  115.82\n"
     ]
    }
   ],
   "source": [
    "aapl_bar = aapl_month[['Open', 'High', 'Low', 'Close']]\n",
    "print(aapl_bar)"
   ]
  },
  {
   "source": [
    "We can even specify both rows and columns using ```loc[]```. The row indices and column names are separated by a comma:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open    High     Low   Close\nDate                                      \n2016-03-31  109.72  109.90  108.88  108.99\n2016-04-30   93.99   94.72   92.51   93.74\n2016-05-31   99.60  100.40   98.82   99.86\n2016-06-30   94.44   95.77   94.30   95.60\n"
     ]
    }
   ],
   "source": [
    "print(aapl_month.loc['2016-03':'2016-06',['Open', 'High', 'Low', 'Close']])"
   ]
  },
  {
   "source": [
    "The subset methods in DataFrame is quite useful. By writing logical statements in square brackets, we can make customized subsets:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close\nDate                                        \n2016-03-31  109.72  109.9000  108.88  108.99\n2016-08-31  105.66  106.5699  105.64  106.10\n2016-09-30  112.46  113.3700  111.80  113.05\n2016-10-31  113.65  114.2300  113.20  113.54\n2016-11-30  111.56  112.2000  110.27  110.52\n2016-12-31  116.65  117.2000  115.43  115.82\n"
     ]
    }
   ],
   "source": [
    "above = aapl_bar[aapl_bar.Close > np.mean(aapl_bar.Close)]\n",
    "print(above)"
   ]
  },
  {
   "source": [
    "#### Data Validation\n",
    "As mentioned, all methods that apply to a Series can also be applied to a DataFrame. Here we add a new column to an existing DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return\n",
      "Date                                                     \n",
      "2016-01-31   94.79   97.3400   94.35   97.34          NaN\n",
      "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
      "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
      "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
      "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
      "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
      "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
      "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
      "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
      "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
      "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
      "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n",
      "<ipython-input-31-f3fe1efaa757>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  aapl_bar['rate_return'] = aapl_bar.Close.pct_change()\n"
     ]
    }
   ],
   "source": [
    "aapl_bar['rate_return'] = aapl_bar.Close.pct_change()\n",
    "print(aapl_bar)"
   ]
  },
  {
   "source": [
    "Here the calculation introduced a NaN value. If the DataFrame is large, we would not be able to observe it. ```isnull()``` provides a convenient way to check abnormal values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Open   High    Low  Close  rate_return\n",
      "Date                                               \n",
      "2016-01-31  False  False  False  False         True\n",
      "2016-02-29  False  False  False  False        False\n",
      "2016-03-31  False  False  False  False        False\n",
      "2016-04-30  False  False  False  False        False\n",
      "2016-05-31  False  False  False  False        False\n",
      "2016-06-30  False  False  False  False        False\n",
      "2016-07-31  False  False  False  False        False\n",
      "2016-08-31  False  False  False  False        False\n",
      "2016-09-30  False  False  False  False        False\n",
      "2016-10-31  False  False  False  False        False\n",
      "2016-11-30  False  False  False  False        False\n",
      "2016-12-31  False  False  False  False        False\n",
      "\n",
      "------------------ separate line -----------------\n",
      "\n",
      "         Open   High    Low  Close rate_return\n",
      "count      12     12     12     12          12\n",
      "unique      1      1      1      1           2\n",
      "top     False  False  False  False       False\n",
      "freq       12     12     12     12          11\n"
     ]
    }
   ],
   "source": [
    "missing = aapl_bar.isnull()\n",
    "print(missing)\n",
    "print('\\n------------------ separate line -----------------\\n')\n",
    "print(missing.describe())"
   ]
  },
  {
   "source": [
    "The row labelled \"unique\" indicates the number of unique values in each column. Since the \"rate_return\" column has 2 unique values, it has at least one missing value.\n",
    "\n",
    "We can deduce the number of missing values by comparing \"count\" with \"freq\". There are 12 counts and 11 False values, so there is one True value which corresponds to the missing value.\n",
    "\n",
    "We can also find the rows with missing values easily:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "             Open   High    Low  Close  rate_return\n",
      "Date                                               \n",
      "2016-01-31  False  False  False  False         True\n"
     ]
    }
   ],
   "source": [
    "print(missing[missing.rate_return == True])"
   ]
  },
  {
   "source": [
    "Usually when dealing with missing data, we either delete the whole row or fill it with some value. As we introduced in the Series chapter, the same method ```dropna()``` and ```fillna()``` can be applied to a DataFrame."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return\n",
      "Date                                                     \n",
      "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
      "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
      "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
      "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
      "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
      "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
      "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
      "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
      "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
      "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
      "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n",
      "\n",
      "---------------------- separate line--------------------\n",
      "\n",
      "              Open      High     Low   Close  rate_return\n",
      "Date                                                     \n",
      "2016-01-31   94.79   97.3400   94.35   97.34     0.000000\n",
      "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
      "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
      "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
      "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
      "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
      "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
      "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
      "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
      "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
      "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
      "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n"
     ]
    }
   ],
   "source": [
    "drop = aapl_bar.dropna()\n",
    "print(drop)\n",
    "print('\\n---------------------- separate line--------------------\\n')\n",
    "fill = aapl_bar.fillna(0)\n",
    "print(fill)"
   ]
  },
  {
   "source": [
    "#### DataFrame Concat\n",
    "We have seen how to extract a Series from a dataFrame. Now we need to consider how to merge a Series or a DataFrame into another one.\n",
    "\n",
    "In Pandas, the function ```concat()``` allows us to merge multiple Series into a DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     AAPL    GOOG\n0  143.50  898.70\n1  144.09  911.71\n2  142.73  906.69\n3  144.18  918.59\n4  143.77  926.99\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')\n",
    "s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')\n",
    "data_frame = pd.concat([s1,s2], axis = 1)\n",
    "print(data_frame)"
   ]
  },
  {
   "source": [
    "The \"axis = 1\" parameter will join two DataFrames by columns:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Date\n2016-01-31    4.578210\n2016-02-29    4.571510\n2016-03-31    4.691256\n2016-04-30    4.540525\n2016-05-31    4.603769\n2016-06-30    4.560173\n2016-07-31    4.646408\n2016-08-31    4.664382\n2016-09-30    4.727830\n2016-10-31    4.732155\n2016-11-30    4.705197\n2016-12-31    4.752037\nFreq: M, Name: log_price, dtype: float64\n\n---------------------- separate line--------------------\n\n              Open      High     Low   Close  rate_return  log_price\nDate                                                                \n2016-01-31   94.79   97.3400   94.35   97.34          NaN   4.578210\n2016-02-29   96.86   98.2300   96.65   96.69    -0.006678   4.571510\n2016-03-31  109.72  109.9000  108.88  108.99     0.127211   4.691256\n2016-04-30   93.99   94.7200   92.51   93.74    -0.139921   4.540525\n2016-05-31   99.60  100.4000   98.82   99.86     0.065287   4.603769\n2016-06-30   94.44   95.7700   94.30   95.60    -0.042660   4.560173\n2016-07-31  104.19  104.5500  103.68  104.21     0.090063   4.646408\n2016-08-31  105.66  106.5699  105.64  106.10     0.018136   4.664382\n2016-09-30  112.46  113.3700  111.80  113.05     0.065504   4.727830\n2016-10-31  113.65  114.2300  113.20  113.54     0.004334   4.732155\n2016-11-30  111.56  112.2000  110.27  110.52    -0.026599   4.705197\n2016-12-31  116.65  117.2000  115.43  115.82     0.047955   4.752037\n"
     ]
    }
   ],
   "source": [
    "log_price = np.log(aapl_bar.Close)\n",
    "log_price.name = 'log_price'\n",
    "print(log_price)\n",
    "print('\\n---------------------- separate line--------------------\\n')\n",
    "concat = pd.concat([aapl_bar, log_price], axis = 1)\n",
    "print(concat)"
   ]
  },
  {
   "source": [
    "We can also join two DataFrames by rows. Consider these two DataFrames:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                Volume  Split Ratio\n",
      "Date                               \n",
      "2016-10-31  26419398.0          1.0\n",
      "2016-11-30  36162258.0          1.0\n",
      "2016-12-31  30586265.0          1.0\n",
      "2017-01-31  49200993.0          1.0\n",
      "2017-02-28  23482860.0          1.0\n",
      "2017-03-31  19661651.0          1.0\n",
      "2017-04-30  20247187.0          1.0\n",
      "\n",
      "---------------------- separate line--------------------\n",
      "\n",
      "              Open     High     Low   Close\n",
      "Date                                       \n",
      "2016-10-31  113.65  114.230  113.20  113.54\n",
      "2016-11-30  111.56  112.200  110.27  110.52\n",
      "2016-12-31  116.65  117.200  115.43  115.82\n",
      "2017-01-31  121.15  121.390  120.62  121.35\n",
      "2017-02-28  137.08  137.435  136.70  136.99\n",
      "2017-03-31  143.72  144.270  143.01  143.66\n",
      "2017-04-30  144.09  144.300  143.27  143.65\n"
     ]
    }
   ],
   "source": [
    "df_volume = aapl_table.loc['2016-10':'2017-04',['Volume', 'Split Ratio']].resample('M').agg(lambda x: x[-1])\n",
    "print(df_volume)\n",
    "print('\\n---------------------- separate line--------------------\\n')\n",
    "df_2017 = aapl_table.loc['2016-10':'2017-04',['Open', 'High', 'Low', 'Close']].resample('M').agg(lambda x: x[-1])\n",
    "print(df_2017)"
   ]
  },
  {
   "source": [
    "Now we merge the DataFrames with our DataFrame 'aapl_bar'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return      Volume  \\\n",
      "Date                                                                    \n",
      "2016-01-31   94.79   97.3400   94.35   97.34          NaN         NaN   \n",
      "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678         NaN   \n",
      "2016-03-31  109.72  109.9000  108.88  108.99     0.127211         NaN   \n",
      "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921         NaN   \n",
      "2016-05-31   99.60  100.4000   98.82   99.86     0.065287         NaN   \n",
      "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660         NaN   \n",
      "2016-07-31  104.19  104.5500  103.68  104.21     0.090063         NaN   \n",
      "2016-08-31  105.66  106.5699  105.64  106.10     0.018136         NaN   \n",
      "2016-09-30  112.46  113.3700  111.80  113.05     0.065504         NaN   \n",
      "2016-10-31  113.65  114.2300  113.20  113.54     0.004334  26419398.0   \n",
      "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599  36162258.0   \n",
      "2016-12-31  116.65  117.2000  115.43  115.82     0.047955  30586265.0   \n",
      "2017-01-31     NaN       NaN     NaN     NaN          NaN  49200993.0   \n",
      "2017-02-28     NaN       NaN     NaN     NaN          NaN  23482860.0   \n",
      "2017-03-31     NaN       NaN     NaN     NaN          NaN  19661651.0   \n",
      "2017-04-30     NaN       NaN     NaN     NaN          NaN  20247187.0   \n",
      "\n",
      "            Split Ratio  \n",
      "Date                     \n",
      "2016-01-31          NaN  \n",
      "2016-02-29          NaN  \n",
      "2016-03-31          NaN  \n",
      "2016-04-30          NaN  \n",
      "2016-05-31          NaN  \n",
      "2016-06-30          NaN  \n",
      "2016-07-31          NaN  \n",
      "2016-08-31          NaN  \n",
      "2016-09-30          NaN  \n",
      "2016-10-31          1.0  \n",
      "2016-11-30          1.0  \n",
      "2016-12-31          1.0  \n",
      "2017-01-31          1.0  \n",
      "2017-02-28          1.0  \n",
      "2017-03-31          1.0  \n",
      "2017-04-30          1.0  \n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([aapl_bar,df_volume],axis = 1)\n",
    "print(concat)"
   ]
  },
  {
   "source": [
    "By default the DataFrame are joined with all of the data. This default options results in zero information loss. We can also merge them by intersection, this is called 'inner join':"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open    High     Low   Close  rate_return      Volume  \\\nDate                                                                  \n2016-10-31  113.65  114.23  113.20  113.54     0.004334  26419398.0   \n2016-11-30  111.56  112.20  110.27  110.52    -0.026599  36162258.0   \n2016-12-31  116.65  117.20  115.43  115.82     0.047955  30586265.0   \n\n            Split Ratio  \nDate                     \n2016-10-31          1.0  \n2016-11-30          1.0  \n2016-12-31          1.0  \n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([aapl_bar,df_volume],axis = 1, join = 'inner')\n",
    "print(concat)"
   ]
  },
  {
   "source": [
    "Only the intersection part was left if use 'inner join' method. Now let's try to append a DataFrame to another one:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return\nDate                                                     \n2016-01-31   94.79   97.3400   94.35   97.34          NaN\n2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n2016-10-31  113.65  114.2300  113.20  113.54          NaN\n2016-11-30  111.56  112.2000  110.27  110.52          NaN\n2016-12-31  116.65  117.2000  115.43  115.82          NaN\n2017-01-31  121.15  121.3900  120.62  121.35          NaN\n2017-02-28  137.08  137.4350  136.70  136.99          NaN\n2017-03-31  143.72  144.2700  143.01  143.66          NaN\n2017-04-30  144.09  144.3000  143.27  143.65          NaN\n"
     ]
    }
   ],
   "source": [
    "append = aapl_bar.append(df_2017)\n",
    "print(append)"
   ]
  },
  {
   "source": [
    "'Append' is essentially to concat two DataFrames by axis = 0, thus here is an alternative way to append:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return\nDate                                                     \n2016-01-31   94.79   97.3400   94.35   97.34          NaN\n2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n2016-10-31  113.65  114.2300  113.20  113.54          NaN\n2016-11-30  111.56  112.2000  110.27  110.52          NaN\n2016-12-31  116.65  117.2000  115.43  115.82          NaN\n2017-01-31  121.15  121.3900  120.62  121.35          NaN\n2017-02-28  137.08  137.4350  136.70  136.99          NaN\n2017-03-31  143.72  144.2700  143.01  143.66          NaN\n2017-04-30  144.09  144.3000  143.27  143.65          NaN\n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
    "print(concat)"
   ]
  },
  {
   "source": [
    "Please note that if the two DataFrame have some columns with the same column names, these columns are considered to be the same and will be merged. It's very important to have the right column names. If we change a column names here:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open      High     Low   Close  rate_return  Change\nDate                                                             \n2016-01-31   94.79   97.3400   94.35   97.34          NaN     NaN\n2016-02-29   96.86   98.2300   96.65   96.69    -0.006678     NaN\n2016-03-31  109.72  109.9000  108.88  108.99     0.127211     NaN\n2016-04-30   93.99   94.7200   92.51   93.74    -0.139921     NaN\n2016-05-31   99.60  100.4000   98.82   99.86     0.065287     NaN\n2016-06-30   94.44   95.7700   94.30   95.60    -0.042660     NaN\n2016-07-31  104.19  104.5500  103.68  104.21     0.090063     NaN\n2016-08-31  105.66  106.5699  105.64  106.10     0.018136     NaN\n2016-09-30  112.46  113.3700  111.80  113.05     0.065504     NaN\n2016-10-31  113.65  114.2300  113.20  113.54     0.004334     NaN\n2016-11-30  111.56  112.2000  110.27  110.52    -0.026599     NaN\n2016-12-31  116.65  117.2000  115.43  115.82     0.047955     NaN\n2016-10-31     NaN  114.2300  113.20  113.54          NaN  113.65\n2016-11-30     NaN  112.2000  110.27  110.52          NaN  111.56\n2016-12-31     NaN  117.2000  115.43  115.82          NaN  116.65\n2017-01-31     NaN  121.3900  120.62  121.35          NaN  121.15\n2017-02-28     NaN  137.4350  136.70  136.99          NaN  137.08\n2017-03-31     NaN  144.2700  143.01  143.66          NaN  143.72\n2017-04-30     NaN  144.3000  143.27  143.65          NaN  144.09\n"
     ]
    }
   ],
   "source": [
    "df_2017.columns = ['Change', 'High','Low','Close']\n",
    "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
    "print(concat)"
   ]
  },
  {
   "source": [
    "Since the column name of 'Open' has been changed, the new DataFrame has an new column named 'Change'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Summary\n",
    "Hereby we introduced the most import part of python: resampling and DataFrame manipulation. We only introduced the most commonly used method in Financial data analysis. There are also many methods used in data mining, which are also beneficial. You can always check the Pandas official documentations for help."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Transcription made by **Gabriel Andres Anzola Tachak**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}